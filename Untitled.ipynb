{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.l\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) wil list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "    \n",
    "import pandas_profiling as pdp\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_data.csv\")\n",
    "test = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=[\"period\",\"game-ver\"])\n",
    "test = test.drop(columns=[\"period\",\"game-ver\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop(columns=[\"y\"])\n",
    "train_y = train[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ランク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_x, test],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"A1-rank\", \"A2-rank\", \"A3-rank\",\"A4-rank\",\"B1-rank\",\"B2-rank\",\"B3-rank\",\"B4-rank\"]:\n",
    "    all_data[c] = all_data[c].fillna(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"A1-rank\", \"A2-rank\", \"A3-rank\",\"A4-rank\",\"B1-rank\",\"B2-rank\",\"B3-rank\",\"B4-rank\"]:\n",
    "    all_data[c] = all_data[c].str.replace(\"c-\", \"1\",regex = False)\n",
    "    all_data[c] = all_data[c].str.replace(\"c+\", \"3\",regex = False)\n",
    "    all_data[c] = all_data[c].str.replace(\"b-\", \"4\",regex = False)\n",
    "    all_data[c] = all_data[c].str.replace(\"b+\", \"6\",regex = False)\n",
    "    all_data[c] = all_data[c].str.replace(\"a-\", \"7\",regex = False)\n",
    "    all_data[c] = all_data[c].str.replace(\"a+\", \"9\",regex = False)\n",
    "    all_data[c] = all_data[c].str.replace(\"s-\", \"10\",regex = False)\n",
    "    all_data[c] = all_data[c].str.replace(\"s+\", \"12\",regex = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"A1-rank\", \"A2-rank\", \"A3-rank\",\"A4-rank\",\"B1-rank\",\"B2-rank\",\"B3-rank\",\"B4-rank\"]:\n",
    "    all_data[c] = all_data[c].str.replace(\"x\", \"13\")\n",
    "    all_data[c] = all_data[c].str.replace(\"c\", \"2\")\n",
    "    all_data[c] = all_data[c].str.replace(\"b\", \"5\")\n",
    "    all_data[c] = all_data[c].str.replace(\"a\", \"8\")\n",
    "    all_data[c] = all_data[c].str.replace(\"s\", \"11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"A1-rank\", \"A2-rank\", \"A3-rank\",\"A4-rank\",\"B1-rank\",\"B2-rank\",\"B3-rank\",\"B4-rank\"]:\n",
    "    all_data[c] =  pd.to_numeric(all_data[c],downcast='signed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"a_sum_rank\"] = 0\n",
    "all_data[\"b_sum_rank\"] = 0\n",
    "\n",
    "all_data[\"a_max_rank\"] = 0\n",
    "all_data[\"b_max_rank\"] = 0\n",
    "\n",
    "all_data[\"a_min_rank\"] = 0\n",
    "all_data[\"b_min_rank\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\koshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\koshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\koshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\koshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\koshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_data)):\n",
    "    all_data[\"a_sum_rank\"][i] =  all_data[\"A1-rank\"][i] + all_data[\"A2-rank\"][i] + all_data[\"A3-rank\"][i] + all_data[\"A4-rank\"][i]\n",
    "    all_data[\"b_sum_rank\"][i] =  all_data[\"B1-rank\"][i] + all_data[\"B2-rank\"][i] + all_data[\"B3-rank\"][i] + all_data[\"B4-rank\"][i]\n",
    "    \n",
    "    all_data[\"a_max_rank\"][i] = max(all_data[\"A1-rank\"][i], all_data[\"A2-rank\"][i], all_data[\"A3-rank\"][i], all_data[\"A4-rank\"][i])\n",
    "    all_data[\"b_max_rank\"][i] = max(all_data[\"B1-rank\"][i], all_data[\"B2-rank\"][i], all_data[\"B3-rank\"][i], all_data[\"B4-rank\"][i])\n",
    "    \n",
    "    all_data[\"a_min_rank\"][i] = min(all_data[\"A1-rank\"][i], all_data[\"A2-rank\"][i], all_data[\"A3-rank\"][i], all_data[\"A4-rank\"][i])\n",
    "    all_data[\"b_min_rank\"][i] = min(all_data[\"B1-rank\"][i], all_data[\"B2-rank\"][i], all_data[\"B3-rank\"][i], all_data[\"B4-rank\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.drop(columns=[\"A1-rank\", \"A2-rank\", \"A3-rank\",\"A4-rank\",\"B1-rank\",\"B2-rank\",\"B3-rank\",\"B4-rank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = all_data.iloc[:train.shape[0],:]\n",
    "test = all_data.iloc[train.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "武器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_x, test],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for c in [\"A1-weapon\", \"A2-weapon\", \"A3-weapon\",\"A4-weapon\",\"B1-weapon\",\"B2-weapon\",\"B3-weapon\",\"B4-weapon\"]:\n",
    "    le.fit(all_data[c].fillna(\"NA\"))\n",
    "    all_data[c] = le.transform(all_data[c].fillna(\"NA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = all_data.iloc[:train.shape[0],:]\n",
    "test = all_data.iloc[train.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "人数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_x, test],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"A_member\"] = 4\n",
    "all_data[\"B_member\"] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_data)):\n",
    "    if pd.isnull(all_data.at[i,\"A4-level\"]):\n",
    "        all_data.at[i,\"A_member\"]=3\n",
    "    if pd.isnull(all_data.at[i,\"B4-level\"]):\n",
    "        all_data.at[i,\"B_member\"]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_data)):\n",
    "    if pd.isnull(all_data.at[i,\"B3-level\"]):\n",
    "        all_data.at[i,\"B_member\"]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = all_data.iloc[:train.shape[0],:]\n",
    "test = all_data.iloc[train.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レベル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_x, test],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"a_sum_level\"] = 0\n",
    "all_data[\"b_sum_level\"] = 0\n",
    "\n",
    "all_data[\"a_max_level\"] = 0\n",
    "all_data[\"b_max_level\"] = 0\n",
    "\n",
    "all_data[\"a_min_level\"] = 0\n",
    "all_data[\"b_min_level\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in [\"A1-level\",\"A2-level\",\"A3-level\",\"A4-level\",\"B1-level\",\"B2-level\",\"B3-level\",\"B4-level\"]:\n",
    "    all_data[i] = all_data[i].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\koshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\koshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\koshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\koshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\koshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_data)):\n",
    "    all_data[\"a_sum_level\"][i] =  all_data[\"A1-level\"][i] + all_data[\"A2-level\"][i] + all_data[\"A3-level\"][i] + all_data[\"A4-level\"][i]\n",
    "    all_data[\"b_sum_level\"][i] =  all_data[\"B1-level\"][i] + all_data[\"B2-level\"][i] + all_data[\"B3-level\"][i] + all_data[\"B4-level\"][i]\n",
    "    \n",
    "    all_data[\"a_max_level\"][i] = max(all_data[\"A1-level\"][i], all_data[\"A2-level\"][i], all_data[\"A3-level\"][i], all_data[\"A4-level\"][i])\n",
    "    all_data[\"b_max_level\"][i] = max(all_data[\"B1-level\"][i], all_data[\"B2-level\"][i], all_data[\"B3-level\"][i], all_data[\"B4-level\"][i])\n",
    "\n",
    "    all_data[\"a_min_level\"][i] = min(all_data[\"A1-level\"][i], all_data[\"A2-level\"][i], all_data[\"A3-level\"][i], all_data[\"A4-level\"][i])\n",
    "    all_data[\"b_min_level\"][i] = min(all_data[\"B1-level\"][i], all_data[\"B2-level\"][i], all_data[\"B3-level\"][i], all_data[\"B4-level\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.drop(columns=[\"A1-level\",\"A2-level\",\"A3-level\",\"A4-level\",\"B1-level\",\"B2-level\",\"B3-level\",\"B4-level\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = all_data.iloc[:train.shape[0],:]\n",
    "test = all_data.iloc[train.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ステージ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_x, test],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for c in [\"stage\"]:\n",
    "    le.fit(all_data[c].fillna(\"NA\"))\n",
    "    all_data[c] = le.transform(all_data[c].fillna(\"NA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = all_data.iloc[:train.shape[0],:]\n",
    "test = all_data.iloc[train.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lobby-mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_x, test],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['regular', 'gachi'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[\"lobby-mode\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for c in [\"lobby-mode\"]:\n",
    "    le.fit(all_data[c].fillna(\"NA\"))\n",
    "    all_data[c] = le.transform(all_data[c].fillna(\"NA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[\"lobby-mode\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = all_data.iloc[:train.shape[0],:]\n",
    "test = all_data.iloc[train.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lobby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_x, test],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for c in [\"lobby\"]:\n",
    "    le.fit(all_data[c].fillna(\"NA\"))\n",
    "    all_data[c] = le.transform(all_data[c].fillna(\"NA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = all_data.iloc[:train.shape[0],:]\n",
    "test = all_data.iloc[train.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_x, test],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for c in [\"mode\"]:\n",
    "    le.fit(all_data[c].fillna(\"NA\"))\n",
    "    all_data[c] = le.transform(all_data[c].fillna(\"NA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = all_data.iloc[:train.shape[0],:]\n",
    "test = all_data.iloc[train.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             int64\n",
       "lobby-mode     int32\n",
       "lobby          int32\n",
       "mode           int32\n",
       "stage          int32\n",
       "A1-weapon      int32\n",
       "A2-weapon      int32\n",
       "A3-weapon      int32\n",
       "A4-weapon      int32\n",
       "B1-weapon      int32\n",
       "B2-weapon      int32\n",
       "B3-weapon      int32\n",
       "B4-weapon      int32\n",
       "a_sum_rank     int64\n",
       "b_sum_rank     int64\n",
       "a_max_rank     int64\n",
       "b_max_rank     int64\n",
       "a_min_rank     int64\n",
       "b_min_rank     int64\n",
       "A_member       int64\n",
       "B_member       int64\n",
       "a_sum_level    int64\n",
       "b_sum_level    int64\n",
       "a_max_level    int64\n",
       "b_max_level    int64\n",
       "a_min_level    int64\n",
       "b_min_level    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "lobby-mode     0\n",
       "lobby          0\n",
       "mode           0\n",
       "stage          0\n",
       "A1-weapon      0\n",
       "A2-weapon      0\n",
       "A3-weapon      0\n",
       "A4-weapon      0\n",
       "B1-weapon      0\n",
       "B2-weapon      0\n",
       "B3-weapon      0\n",
       "B4-weapon      0\n",
       "a_sum_rank     0\n",
       "b_sum_rank     0\n",
       "a_max_rank     0\n",
       "b_max_rank     0\n",
       "a_min_rank     0\n",
       "b_min_rank     0\n",
       "A_member       0\n",
       "B_member       0\n",
       "a_sum_level    0\n",
       "b_sum_level    0\n",
       "a_max_level    0\n",
       "b_max_level    0\n",
       "a_min_level    0\n",
       "b_min_level    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train_x,train_y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "nawabari_train = train.loc[train[\"lobby-mode\"]==1]\n",
    "gachi_train = train.loc[train[\"lobby-mode\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nawabari_train_x = nawabari_train.drop([\"y\"],axis=1)\n",
    "nawabari_train_y = nawabari_train[\"y\"]\n",
    "gachi_train_x = gachi_train.drop([\"y\"],axis=1)\n",
    "gachi_train_y = gachi_train[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nawabari_train_x = nawabari_train_x.drop(columns=[\"a_sum_rank\",\"b_sum_rank\",\"id\"])\n",
    "gachi_train_x = gachi_train_x.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nawabari_test_x = test.loc[test[\"lobby-mode\"]==1]\n",
    "gachi_test_x = test[test[\"lobby-mode\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "nawabari_test_x = nawabari_test_x.drop(columns=[\"a_sum_rank\",\"b_sum_rank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nawabari_id = nawabari_test_x[\"id\"]\n",
    "gachi_id = gachi_test_x[\"id\"]\n",
    "nawabari_test_x = nawabari_test_x.drop(columns=[\"id\"])\n",
    "gachi_test_x = gachi_test_x.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lobby-mode     0\n",
       "lobby          0\n",
       "mode           0\n",
       "stage          0\n",
       "A1-weapon      0\n",
       "A2-weapon      0\n",
       "A3-weapon      0\n",
       "A4-weapon      0\n",
       "B1-weapon      0\n",
       "B2-weapon      0\n",
       "B3-weapon      0\n",
       "B4-weapon      0\n",
       "a_max_rank     0\n",
       "b_max_rank     0\n",
       "a_min_rank     0\n",
       "b_min_rank     0\n",
       "A_member       0\n",
       "B_member       0\n",
       "a_sum_level    0\n",
       "b_sum_level    0\n",
       "a_max_level    0\n",
       "b_max_level    0\n",
       "a_min_level    0\n",
       "b_min_level    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nawabari_test_x.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import  XGBClassifier\n",
    "model1 = XGBClassifier(n_estimators = 20, random_state= 71)\n",
    "model2 = XGBClassifier(n_estimators = 20, random_state= 71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model1_lr = LogisticRegression(solver=\"lbfgs\", max_iter=300)\n",
    "model2_lr = LogisticRegression(solver=\"lbfgs\", max_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(nawabari_train_x,nawabari_train_y)\n",
    "pred_xgb_nawabari = model1.predict_proba(nawabari_test_x)[:,1]\n",
    "\n",
    "model1_lr.fit(nawabari_train_x,nawabari_train_y)\n",
    "pred_lr_nawabari = model1_lr.predict_proba(nawabari_test_x)[:,1]\n",
    "\n",
    "pred = pred_xgb_nawabari*0.8 + pred_lr_nawabari*0.2\n",
    "pred_label = np.where(pred>0.5,1,0)\n",
    "submission_nawabari = pd.DataFrame({\"id\":nawabari_id.astype('int64'),\"y\":pred_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koshi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model2.fit(gachi_train_x,gachi_train_y)\n",
    "pred_gachi = model2.predict_proba(gachi_test_x)[:,1]\n",
    "\n",
    "model2_lr.fit(gachi_train_x,gachi_train_y)\n",
    "pred_lr_gachi = model2_lr.predict_proba(gachi_test_x)[:,1]\n",
    "\n",
    "pred = pred_gachi*0.8 + pred_lr_gachi*0.2\n",
    "pred_label = np.where(pred_gachi > 0.5,1,0)\n",
    "submission_gachi = pd.DataFrame({\"id\":gachi_id.astype('int64'),\"y\":pred_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission =  pd.concat([submission_nawabari, submission_gachi])\n",
    "submission = submission.sort_values(\"id\")\n",
    "submission.head()\n",
    "submission.to_csv(\"submission_5.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
